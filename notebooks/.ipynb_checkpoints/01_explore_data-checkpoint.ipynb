{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\">Show/Hide Code</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../../shared/utilz_includez.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/Cornell-University/movie-dialog-corpus ==> http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../dataset/cornell_movie_dialogs_corpus\"\n",
    "sepz = '+++$+++'\n",
    "listing_file='movie_titles_metadata.txt'\n",
    "full_convoz_file = 'movie_lines.txt'\n",
    "convoz_listing_file = 'movie_conversations.txt'\n",
    "target_genres = ['romance', 'comedy', 'drama', 'sci-fi', 'mystery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_movies_list = {}\n",
    "idx_target_movies_list = []\n",
    "\n",
    "target_convoz_list = {}\n",
    "idx_target_convoz_list = []\n",
    "\n",
    "x_labelz = []\n",
    "y_labelz = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_year(year):\n",
    "    return int(year.strip()[0:4] ) >= 2000 \n",
    "\n",
    "def is_within_rating(imdbrating):\n",
    "    return float(imdbrating.strip() ) >= 6\n",
    "\n",
    "def is_within_genres( genres ):\n",
    "    for g in genres:\n",
    "        if g.strip() in target_genres:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_from_target_movie(mid):\n",
    "    #print( f\"'{mid}'\" )\n",
    "    return str(mid).strip() in idx_target_movies_list \n",
    "\n",
    "def turnStrToList(lines_list):#todo regex\n",
    "    listz = str(lines_list).strip()[1:-2].replace('\\'', '').split(',')\n",
    "    #print( repr(listz) )\n",
    "    return listz\n",
    "    \n",
    "def get_last_statement( lines_list ):     \n",
    "    return turnStrToList( lines_list )[-1]\n",
    "\n",
    "\n",
    "def get_first_statement( lines_list ): \n",
    "    return turnStrToList( lines_list )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 532 suitable samples\n",
      "EG: ['m0 ', ' 10 things i hate about you ', ' 1999 ', ' 6.90 ', ' 62847 ', \" ['comedy', 'romance']\\n\"]\n",
      "EG: ['m616 ', ' zulu dawn ', ' 1979 ', ' 6.40 ', ' 1911 ', \" ['action', 'adventure', 'drama', 'history', 'war']\\n\"]\n"
     ]
    }
   ],
   "source": [
    "with open( f\"{dataset_dir}/{listing_file}\", 'r', encoding='iso-8859-1') as fd:\n",
    "    for row in fd.readlines():\n",
    "        # id, title, year, IMDB rating, # votes, genres_list \n",
    "        rec = row.split( sepz )\n",
    "        # print( rec )\n",
    "        \n",
    "        if is_within_year( rec[2]) or \\\n",
    "            is_within_rating( rec[3]) or \\\n",
    "                is_within_genres( rec[5]):\n",
    "            rid = f\"{rec[0].strip()}\" \n",
    "            target_movies_list[ rid ] = rec\n",
    "            idx_target_movies_list.append( rid )\n",
    "            \n",
    "        \n",
    "print( f\"Found { len(target_movies_list) } suitable samples\")\n",
    "print( f\"EG: { target_movies_list[ idx_target_movies_list[0]] }\")\n",
    "print( f\"EG: {target_movies_list[ idx_target_movies_list[-1]] }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "def parseConvo(rec, is_first=False, is_last=False ): \n",
    "    global counter\n",
    "    #line_id, u_id, m_id, u_name, line_str\n",
    "    rec = row.split( sepz )\n",
    "    print( rec )\n",
    "    if is_from_target_movie( rec[2] ):            \n",
    "        #rid = f\"{rec[0]}_{rec[1]}\"        \n",
    "        first_line = get_first_statement(rec[3])\n",
    "        last_line = get_last_statement(rec[3])\n",
    "        \n",
    "        target_convoz_list[ rid ] = [ *rec[0:3], turnStrToList(rec[3]), first_line, last_line ]\n",
    "        idx_target_convoz_list.append( rid )            \n",
    "                \n",
    "        if not is_last:\n",
    "            x_labelz.append( last_line )\n",
    "            \n",
    "        if not is_first: \n",
    "            y_labelz.append( first_line )\n",
    "    else:        \n",
    "        print( f\"NOT IN TARGET '{rec[2]}' :: {rec}\" )\n",
    "    \n",
    "    print( f\"XXX: {x_labelz}\" )\n",
    "    print(f\"YYY: {y_labelz}\\n\")\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if counter == 7:\n",
    "        rec.trim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237283 ===  237283 suitable samples\n",
      "EG: They do not! --> They do to!\n",
      "EG: Good ones, yes, Mr Vereker. Gentlemen who can ride and shoot --> Colonel Durnford... William Vereker. I hear you 've been seeking Officers?\n"
     ]
    }
   ],
   "source": [
    "x_labelz = []\n",
    "y_labelz = []\n",
    "\n",
    "counter = 0\n",
    "with open( f\"{dataset_dir}/{full_convoz_file}\", 'r', encoding='iso-8859-1') as fd:    \n",
    "    dcurrent, dnext = None, None     \n",
    "    dcurrent = fd.readline()\n",
    "    if dcurrent:\n",
    "        dcurrent = dcurrent.split( sepz )\n",
    "        while True:\n",
    "        #line_id, u_id, m_id, u_name, line_str \n",
    "            dnext = fd.readline()\n",
    "#             if counter == 7:\n",
    "#                 break\n",
    "            if dnext:\n",
    "                dnext = dnext.split( sepz )\n",
    "                \n",
    "                if dnext[2].strip() == dcurrent[2].strip() and \\\n",
    "                    is_from_target_movie( dnext[2]) and \\\n",
    "                        dnext[1].strip() != dcurrent[1].strip(): \n",
    "                    x_labelz.append( dcurrent[4].strip())\n",
    "                    y_labelz.append( dnext[4].strip())\n",
    "            \n",
    "#                 print(f\">>>{dcurrent}\\n>>>{dnext}\" )                      \n",
    "#                 print(f\">>>{x_labelz}\\n>>>{y_labelz}\" )\n",
    "                \n",
    "                dcurrent = dnext\n",
    "                dnext = None\n",
    "                counter += 1\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "\n",
    "print( f\"Found { len(x_labelz) } ===  { len(y_labelz) } suitable samples\")\n",
    "print( f\"EG: { x_labelz[0]} --> {y_labelz[0]}\")\n",
    "print( f\"EG: { x_labelz[-1]} --> {y_labelz[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import nltk\n",
    "#import textblob\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performanceReport(pred_y, target_y, title):\n",
    "    print( f\"Accuracy Score: { accuracy_score(target_y, pred_y)}\\n\")\n",
    "    print( f\"Classification Report: \\n{ classification_report(target_y, pred_y)}\\n\")\n",
    "    print( f\"Confusion Matrix: \\n { confusion_matrix(target_y, pred_y)}\")\n",
    "    \n",
    "    \n",
    "def preprocess(row):\n",
    "    # remove punkts and numbers + make lower \n",
    "    res = str(row).lower()\n",
    "    res = re.sub( \"[^\\w_\\s\\']+\", '', res) ## keep possesive forms\n",
    "    return res\n",
    "\n",
    "def encode_bow(dset, ngramz=(1,1)):\n",
    "    encoder = CountVectorizer(ngram_range=ngramz )\n",
    "    encoded_matrix = encoder.fit_transform( dset )\n",
    "    return encoded_matrix, encoder\n",
    "\n",
    "def encode_tfidf(dset, ngramz=(1,1)):\n",
    "    encoder = TfidfVectorizer(ngram_range=ngramz )\n",
    "    encoded_matrix = encoder.fit_transform( dset )\n",
    "    return encoded_matrix, encoder\n",
    "\n",
    "def encode_with(dset, encoder):\n",
    "    return encoder.transform( dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: x, y = 158979, 158979\n",
      "Training Set EG.0: x, y = Ah, er war gleich tot - I mean, sie war gleich tot - brauchen kein angst zu. Ein moment...Wart ein bissel...Wartein bissel. Fraulein Schmidt!, I was told that he did not die at once.\n",
      "Training Set EG.-1: x, y = I know that., I didn't mean to hit you.\n",
      "\n",
      "Testing Set: x, y = 78304, 78304\n",
      "Testing Set EG.0: x, y = Did you tell Veronica?, She called me.\n",
      "Testing Set EG.-1: x, y = A porco?, She's saying he's a-- a--  porco.\n"
     ]
    }
   ],
   "source": [
    "## train/test split << PS: can combine with vectorizer by passing preprocessin func\n",
    "x_train, x_test, y_train, y_test = train_test_split( x_labelz, y_labelz, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"Training Set: x, y = { len(x_train) }, { len(y_train) }\")\n",
    "print(f\"Training Set EG.0: x, y = { x_train[0] }, { y_train[0] }\")\n",
    "print(f\"Training Set EG.-1: x, y = { x_train[-1] }, { y_train[-1] }\")\n",
    "\n",
    "print(f\"\\nTesting Set: x, y = { len(x_test) }, { len(y_test) }\")\n",
    "print(f\"Testing Set EG.0: x, y = { x_test[0] }, { y_test[0] }\")\n",
    "print(f\"Testing Set EG.-1: x, y = { x_test[-1] }, { y_test[-1] }\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set EG.0: x, y = ah er war gleich tot  i mean sie war gleich tot  brauchen kein angst zu ein momentwart ein bisselwartein bissel fraulein schmidt ---> i was told that he did not die at once\n",
      "Training Set EG.-1: x, y = i know that ---> i didn't mean to hit you\n",
      "Testing Set EG.0: x, y = did you tell veronica ---> she called me\n",
      "Testing Set EG.-1: x, y = a porco ---> she's saying he's a a  porco\n"
     ]
    }
   ],
   "source": [
    "## preprocess\n",
    "x_train = [ preprocess(x) for x in x_train ]\n",
    "y_train = [ preprocess(x) for x in y_train ]\n",
    "x_test = [ preprocess(x) for x in x_test ]\n",
    "y_test = [ preprocess(x) for x in y_test ]\n",
    "print(f\"Training Set EG.0: x, y = { x_train[0] } ---> { y_train[0] }\")\n",
    "print(f\"Training Set EG.-1: x, y = { x_train[-1] } ---> { y_train[-1] }\")\n",
    "\n",
    "print(f\"Testing Set EG.0: x, y = { x_test[0] } ---> { y_test[0] }\")\n",
    "print(f\"Testing Set EG.-1: x, y = { x_test[-1] } ---> { y_test[-1] }\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set EG.0: x, y =   (0, 33634)\t0.18588479244259754\n",
      "  (0, 14876)\t0.18406789329022877\n",
      "  (0, 4258)\t0.2048299136163163\n",
      "  (0, 4259)\t0.21182199415651926\n",
      "  (0, 24921)\t0.21182199415651926\n",
      "  (0, 12122)\t0.39204186784748907\n",
      "  (0, 45058)\t0.2048299136163163\n",
      "  (0, 1943)\t0.21182199415651926\n",
      "  (0, 20966)\t0.2048299136163163\n",
      "  (0, 5017)\t0.21182199415651926\n",
      "  (0, 34962)\t0.17826556670046423\n",
      "  (0, 23917)\t0.08820275541507147\n",
      "  (0, 39598)\t0.4096598272326326\n",
      "  (0, 15876)\t0.4096598272326326\n",
      "  (0, 43146)\t0.24581162575677054\n",
      "  (0, 12692)\t0.14506471044873745\n",
      "  (0, 1324)\t0.125940887235991 \n",
      "Testing Set EG.0: x, y =   (0, 44776)\t0.17406030761620256\n",
      "  (0, 42590)\t0.8088469304347322\n",
      "  (0, 38426)\t0.40637461174700784\n",
      "  (0, 10515)\t0.38772326131705437\n",
      "\n",
      "The Encoder: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      " Vocab: 45078, ['ah', 'er', 'war', 'gleich']\n"
     ]
    }
   ],
   "source": [
    "## encode TFIDF \n",
    "encoded_x_train, encoder_x = encode_tfidf(x_train )\n",
    "encoded_y_train = encode_with( y_train, encoder_x)\n",
    "encoded_x_test = encode_with( x_test, encoder_x)\n",
    "encoded_y_test = encode_with( y_test, encoder_x)\n",
    "                                            \n",
    "print(f\"Training Set EG.0: x, y = { encoded_x_train[0] } \" )\n",
    "print(f\"Testing Set EG.0: x, y = {encoded_x_test[0] }\")\n",
    "\n",
    "\n",
    "print(f\"\\nThe Encoder: {encoder_x}\\n Vocab: { len(encoder_x.vocabulary_) }, {list(encoder_x.vocabulary_.keys())[:4] }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 64)          2884992   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,985,098\n",
      "Trainable params: 2,985,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_unitz = 128\n",
    "vocab = list(encoder_x.vocabulary_.keys() ) \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding( input_dim =len(vocab), output_dim=64 ),\n",
    "    keras.layers.LSTM( hidden_unitz ),\n",
    "    keras.layers.Dense( 10 )\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
